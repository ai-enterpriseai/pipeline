import asyncio
import time
from pathlib import Path

try:
    from src.pipeline.processor import Processor
    from src.pipeline.embedder import Embedder
    from src.pipeline.indexer import Indexer
    from src.pipeline.utils.configs import (
        ProcessorConfig,
        EmbedderConfig,
        IndexerConfig,
    )
except ModuleNotFoundError as exc:
    missing = str(exc).split("No module named")[-1].strip().strip("'")
    print(
        f"Missing dependency: {missing}. Install requirements with 'pip install -r requirements.txt' "
        "and ensure all optional packages are available."
    )
    raise SystemExit(1) from exc

def create_dummy_files(path: Path, count: int = 300) -> None:
    """Create dummy text files for performance testing."""
    path.mkdir(parents=True, exist_ok=True)
    for i in range(count):
        (path / f"file_{i}.txt").write_text(f"dummy content {i} " * 50)  # Make files larger for realistic testing

def measure_time(label: str):
    start = time.perf_counter()
    yield
    end = time.perf_counter()
    print(f"{label}: {end - start:.2f}s")

async def main():
    print("üöÄ Starting Cogit Performance Assessment")
    print("=" * 50)
    
    tmp_dir = Path("temp_data")
    
    # Create dummy files
    print("üìÅ Creating test files...")
    create_dummy_files(tmp_dir)  # Run synchronously for simplicity
    print(f"‚úÖ Created {len(list(tmp_dir.glob('*.txt')))} test files")

    # Configure components with mock values for testing
    processor_config = ProcessorConfig()
    embedder_config = EmbedderConfig()
    
    # Mock indexer config for testing (no actual DB connection needed)
    indexer_config = IndexerConfig(
        collection_name="test_collection",
        url="http://localhost:6333",  # Default Qdrant URL
        qdrant_api_key="mock_api_key",
        use_local_db=True,  # Use local for testing
        batch_size=50,  # Smaller batch for testing
    )

    processor = Processor(processor_config)
    embedder = Embedder(embedder_config)
    
    # Note: For this assessment, we'll focus on processor and embedder performance
    # Indexer requires actual database connection, so we'll test up to embedding generation
    
    total_start = time.perf_counter()
    
    try:
        # Stage 1: Document Loading
        print("\nüìö Stage 1: Document Loading")
        load_start = time.perf_counter()
        docs = await processor.load_documents(tmp_dir)
        load_end = time.perf_counter()
        load_time = load_end - load_start
        print(f"‚úÖ Loaded {len(docs)} documents in {load_time:.2f}s")
        print(f"üìä Loading rate: {len(docs)/load_time:.1f} docs/sec")

        # Stage 2: Document Processing
        print("\n‚öôÔ∏è  Stage 2: Document Processing (chunking, deduplication)")
        process_start = time.perf_counter()
        processed = []
        async for doc in processor.process_documents(docs):
            if doc:
                processed.append(doc)
        process_end = time.perf_counter()
        process_time = process_end - process_start
        print(f"‚úÖ Processed {len(processed)} documents in {process_time:.2f}s")
        print(f"üìä Processing rate: {len(processed)/process_time:.1f} docs/sec")

        # Stage 3: Embedding Generation (without database upload)
        print("\nüß† Stage 3: Embedding Generation")
        embed_start = time.perf_counter()
        
        total_chunks = sum(len(doc.chunks) for doc in processed)
        embedded_count = 0
        
        for doc in processed:
            if doc.chunks:
                # Extract text from chunk tuples (text, metadata)
                texts = [chunk[0] for chunk in doc.chunks]  # chunk[0] is the text content
                dense_embeddings = await embedder.get_dense_embeddings(texts)
                
                # Generate sparse embeddings  
                sparse_embeddings = await embedder.get_sparse_embeddings(texts)
                
                embedded_count += len(texts)
        
        embed_end = time.perf_counter()
        embed_time = embed_end - embed_start
        print(f"‚úÖ Generated embeddings for {embedded_count} chunks in {embed_time:.2f}s")
        print(f"üìä Embedding rate: {embedded_count/embed_time:.1f} chunks/sec")

        # Overall Performance Summary
        total_time = time.perf_counter() - total_start
        print("\n" + "=" * 50)
        print("üìã PERFORMANCE ASSESSMENT SUMMARY")
        print("=" * 50)
        print(f"üïê Total pipeline time: {total_time:.2f}s")
        print(f"üìÑ Files processed: {len(docs)}")
        print(f"üìù Chunks generated: {total_chunks}")
        print(f"‚ö° Overall throughput: {len(docs)/total_time:.1f} docs/sec")
        print("\nüìä Stage Breakdown:")
        print(f"  ‚Ä¢ Loading: {load_time:.2f}s ({load_time/total_time*100:.1f}%)")
        print(f"  ‚Ä¢ Processing: {process_time:.2f}s ({process_time/total_time*100:.1f}%)")
        print(f"  ‚Ä¢ Embedding: {embed_time:.2f}s ({embed_time/total_time*100:.1f}%)")
        
        # Performance Analysis
        print("\nüîç PERFORMANCE ANALYSIS:")
        if load_time > total_time * 0.4:
            print("‚ö†Ô∏è  Loading is a major bottleneck (>40% of total time)")
            print("   üí° Consider: async file loading, parallel processing")
        
        if embed_time > total_time * 0.5:
            print("‚ö†Ô∏è  Embedding is a major bottleneck (>50% of total time)")
            print("   üí° Consider: batching, GPU acceleration, async processing")
            
        if total_time > 60:  # More than 1 minute for 300 files
            print("‚ö†Ô∏è  Overall performance is slow")
            print("   üí° Consider: pipeline parallelization, caching, optimization")
        else:
            print("‚úÖ Overall performance is acceptable")

    except Exception as e:
        print(f"‚ùå Error during assessment: {e}")
    finally:
        await processor.close()
        # Clean up test files
        import shutil
        if tmp_dir.exists():
            shutil.rmtree(tmp_dir)
            print(f"üßπ Cleaned up test directory")

if __name__ == "__main__":
    asyncio.run(main())
